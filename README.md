# Decision-Trees-Random-Forests-AdaBoost-XGBoost

## Decisionn Tree

A decision tree is a decision support tool that uses a tree-like model of 
decisions and their possible consequences, including chance event 
outcomes, resource costs, and utility. It is one way to display an 
algorithm that only contains conditional control statements.


1. Regression Tree 
For continuous quantitative target variable. 
Eg. Predicting rainfall, predicting revenue, predicting marks etc. 
2. Classification Tree 
For discrete categorical target variables 
Eg. Predicting High or Low, Win or Loss, Healthy or Unhealthy etc 

## Ensemble Methods

1. Bagging 
2. Random Forest 
3. Boosting
   
Problem with normal decision tree 
â€¢ High Variance

## Bagging

1. While bagging pruning is not done, Full length trees are grown 
2. Individual trees have high variance and low bias, averaging reduces the 
variance 
3. In regression, we take the average of predicted values 
4. In Classification, we take majority vote i.e. most predicted class will be 
taken as the final prediction

## Boosting

Process of turning a weak learner into a strong learner 
1. Gradient Boost 
2. Ada Boost 
3. XG Boost

